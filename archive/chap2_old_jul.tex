\chapter{Background and Related Work}\label{ch:2}

The significant challenges of manual course articulation, detailed in the previous chapter, have prompted a range of research efforts aimed at automating the process~\cite{ma_course_recommendation_2017, PardosCourse2Vec2019, pardos-articulation-2019, JiangPardosMulti2VecEDM2020,XuPardosSubwordEmbeddings2024}. These technological interventions have evolved in sophistication, mirroring broader advancements in natural language processing (NLP) and machine learning~\cite{shiferaw2024}. A critical review of this literature reveals a clear trajectory from simple statistical methods to complex deep learning models, with each stage introducing new capabilities while also exposing new limitations~\cite{pardos-articulation-2019}. This evolution illuminates the path toward a more robust and scalable solution.

\section{Keyword and Statistical Methods}\label{ch:2.1}
The earliest attempts at automating course comparison relied on foundational text analysis techniques that, while computationally simple, lack semantic depth. The most basic systems are essentially search engines or databases that depend on exact keyword matching or pre-populated tables of known equivalencies~\cite{shamrock}. These systems are inherently brittle; they cannot recognize semantic variations (e.g., equating ``Introduction to Programming'' with ``Fundamentals of Computer Science I'') and require continuous manual updates to remain relevant~\cite{shiferaw2024}.

A more advanced statistical method, Term Frequency-Inverse Document Frequency (TF-IDF), improves upon keyword matching by vectorizing documents and weighting terms based on their importance. A term's frequency within a single document (TF) is balanced against its rarity across a corpus (IDF)~\cite{AIZAWA200345}. This allows the model to assign higher importance to distinctive terms (e.g., ``calculus'') and lower importance to common words (e.g., ``the,'' ``a,'' ``is'')~\cite{AIZAWA200345}. While TF-IDF has been a workhorse for information retrieval, its fundamental limitation is a complete lack of semantic understanding~\cite{AIZAWA200345}. Models in this class treat words as discrete, unrelated tokens; they cannot grasp that ``calculus'' and ``differentiation'' are related concepts, nor can they distinguish between different meanings of the same word.

\section{Static Semantic Representations}\label{ch:2.2}
The development of word embeddings represented the first major leap toward a true semantic understanding of course content. Models like Word2Vec and GloVe, trained on vast text corpora, learn to represent words as dense vectors where words with similar meanings are positioned closer to one another in the vector space. This innovation enabled a more nuanced comparison of texts than was possible with TF-IDF. These techniques have been applied to content-based course recommendation by creating a single vector for a course description, typically by averaging the vectors of its constituent words~\cite{pardos10.1145/3330430.3333622}.

Despite this advancement, these models produce static embeddings where each word is assigned a single, fixed vector regardless of its context~\cite{devlin2019bertpretrainingdeepbidirectional}. This is a significant drawback, as it fails to account for polysemy---words with multiple meanings. For instance, the word ``bank'' would have the same vector in ``river bank'' and ``bank account.'' Furthermore, the practice of averaging all word vectors to create a document-level representation is a crude heuristic that can dilute or lose critical semantic information~\cite{reimers-2019-sentence-bert}.

\section{Contextual Semantic Representations}\label{ch:2.3}
The introduction of the transformer architecture, specifically models like Bidirectional Encoder Representations from Transformers (BERT), revolutionized NLP by enabling the generation of contextual embeddings~\cite{devlin2019bertpretrainingdeepbidirectional}. In these models, a word's vector representation is dynamically influenced by the words surrounding it, allowing the model to disambiguate word meanings and capture a much richer semantic representation~\cite{devlin2019bertpretrainingdeepbidirectional}. Architectures such as Sentence-BERT (SBERT) were subsequently developed to fine-tune these models to produce semantically meaningful embeddings for entire sentences or paragraphs, which can then be efficiently compared using metrics like cosine similarity~\cite{reimers-2019-sentence-bert}.

\section{Direct LLM Classification}\label{ch:2.4}
A more recent evolution involves the direct application of large-scale generative models, or Large Language Models (LLMs) like GPT-4 and Gemini, for classification. As explored in preliminary work for this thesis, these models can be instructed via prompt engineering and in-context learning to perform pairwise comparisons of course descriptions and render a judgment on their equivalency. While these experiments yielded promising accuracy, they also uncovered significant practical limitations. The direct use of LLMs for this task is computationally expensive, requiring full text descriptions to be sent to a model API for every comparison. Performance is acutely sensitive to prompt phrasing, and the decision-making process is a ``black box,'' providing a categorical output without a quantifiable similarity score. This opacity makes it difficult to rank matches, set thresholds, or provide transparent justifications. This approach is also ill-suited for handling complex one-to-many or many-to-many articulation scenarios.

\section{Enrollment-Based Approaches}\label{ch:2.5}
Parallel research efforts have leveraged different data sources entirely. A notable body of work has demonstrated that course similarity can be predicted by analyzing student enrollment data~\cite{pardos2018connectionistrecommendationwildutility, JiangPardosMulti2VecEDM2020}. Models such as \emph{course2vec} learn embeddings from the patterns of which courses students take together, operating on the principle that courses taken in the same semester or sequence likely share a topical relationship~\cite{pardos2018connectionistrecommendationwildutility}. While powerful, this behavioral approach is constrained by its reliance on large-scale, proprietary institutional datasets. This raises significant data privacy concerns and limits the model's generalizability, as it cannot be used to compare courses between two institutions with no history of student transfer between them~\cite{slade10.1177/0002764213479366}. This approach is therefore not a universal solution for the broader course articulation problem.

This review of varied approaches reveals a fundamental trade-off: as models gain semantic power, they tend to become more computationally intensive, less interpretable, or more demanding of specialized or private data. The limitations of direct LLM classification (cost, opacity) and enrollment-based methods (data privacy, limited access) point toward a gap in the existing research for a new paradigm~\cite{pardos-articulation-2019, slade10.1177/0002764213479366}. An effective solution must harness the semantic power of large pre-trained models without inheriting their operational burdens. The literature thus indicates a need for an intelligent, hybrid framework that decouples deep semantic representation from final classification. This conceptual gap forms the central motivation for the methodology proposed in this thesis.

Table~\ref{tbl:taxonomy} summarizes the primary methods for determining course transferability.

\begin{table}[tb]
    \captionsetup{skip=5pt}
    \centering
    \setlength{\tabcolsep}{10pt} % Default value: 6pt
    \renewcommand{\arraystretch}{1.5}  % Provide more space between table rows, if you prefer
    \caption{Comparative Taxonomy of Course Equivalency Determination Methods}\label{tbl:taxonomy}
    \resizebox{\columnwidth}{!}{
        \begin{tabular}{>{\raggedright\arraybackslash}p{2.25cm}>{\raggedright\arraybackslash}p{3cm}>{\raggedright\arraybackslash}p{1.75cm}>{\raggedright\arraybackslash}p{1.9cm}>{\raggedright\arraybackslash}p{3.75cm}>{\raggedright\arraybackslash}p{3.75cm}}
            \toprule
            Approach                                       & Key Characteristics                                                   & Data Source(s)              & Semantic Capability & Strengths                                                                                     & Limitations                   \\
            \midrule
            Manual Review                                  & Human experts (advisors, faculty) compare syllabi descriptions.       & Course Catalogs, Syllabi    & High (Human-level)  & Nuanced, context-aware, trusted by faculty.                                                   & Extremely slow, not scalable, subjective, prone to inconsistency. \\
            Keyword/ TF-IDF                                & Bag-of-words representation, statistical term weighting.              & Course Catalogs             & None to Low         & Simple, computationally cheap, easy to implement.                                             & Fails to capture synonyms, context, or true semantic meaning \\
            Static\hspace{3em}Embeddings (Word2Vec/ GloVe) & Pre-trained word vectors, often averaged for document representation. & Course Catalogs             & Medium              & Captures word-level semantics, better than TF-IDF.                                            & Context-insensitive, averaging vectors loses information. \\
            Enrollment-Based (e.g., course2vec)            & Embeddings learned from student co-enrollment patterns.               & Proprietary Student Records & High (Behavioral)   & Captures functional relationships between courses, highly predictive.                         & Requires access to sensitive private data, not generalizable, privacy concerns. \\
            Direct LLM Classification                      & End-to-end classification using prompt engineering.                   & Course Catalogs             & Very High           & High accuracy potential, understands complex language.                                        & Computationally expensive, ``black box'' opacity, prompt sensitive, no quantifiable similarity score, risk of hallucinations. \\
            Proposed Method (Embeddings + ML)              & Deep contextual embeddings as features for traditional classifiers.   & Course Catalogs             & Very High           & State-of-the-art accuracy, computationally efficient, quantifiable, uses public data only.  & Relies on the quality of the pre-trained embedding model. \\
            \bottomrule
        \end{tabular}
    }
\end{table}