\chapter{Background and Related Work}\label{ch:2}

The significant challenges of manual course articulation, detailed in the previous chapter, have prompted a range of research efforts aimed at automating the process~\cite{ma_course_recommendation_2017, PardosCourse2Vec2019, pardos-articulation-2019, JiangPardosMulti2VecEDM2020,XuPardosSubwordEmbeddings2024}.  These technological interventions have evolved in sophistication, mirroring broader advancements in natural language processing (NLP) and machine learning~\cite{shiferaw2024}.  A critical review of this literature reveals a clear trajectory from simple statistical methods to complex deep learning models, with each stage introducing new capabilities while also exposing new limitations~\cite{pardos-articulation-2019}.  This evolution illuminates the path toward a more robust and scalable solution.

\section{Keyword and Statistical Methods}\label{ch:2.1}
The earliest attempts at automating course comparison relied on foundational text analysis techniques that, while computationally simple, lack semantic depth.  The most basic systems are essentially search engines or databases that depend on exact keyword matching or pre-populated tables of known equivalencies~\cite{shamrock}.  These systems are inherently brittle; they cannot recognize semantic variations (e.g., equating ``Introduction to Programming'' with ``Fundamentals of Computer Science I'') and require continuous manual updates to remain relevant~\cite{shiferaw2024}.

A more advanced statistical method, Term Frequency-Inverse Document Frequency (TF-IDF), improves upon keyword matching by vectorizing documents and weighting terms based on their importance.  A term's frequency within a single document (TF) is balanced against its rarity across a corpus (IDF)~\cite{AIZAWA200345}.  This allows the model to assign higher importance to distinctive terms (e.g., ``calculus'') and lower importance to common words (e.g., ``the,'' ``a,'' ``is'')~\cite{AIZAWA200345}.  While TF-IDF has been a workhorse for information retrieval, its fundamental limitation is a complete lack of semantic understanding~\cite{AIZAWA200345}.  Models in this class treat words as discrete, unrelated tokens;  they cannot grasp that ``calculus'' and ``differentiation'' are related concepts, nor can they distinguish between different meanings of the same word.

\section{Static Semantic Representations}\label{ch:2.2}
The development of word embeddings represented the first major leap toward a true semantic understanding of course content.  Models like Word2Vec and GloVe, trained on vast text corpora, learn to represent words as dense vectors where words with similar meanings are positioned closer to one another in the vector space.  This innovation enabled a more nuanced comparison of texts than was possible with TF-IDF.  These techniques have been applied to content-based course recommendation by creating a single vector for a course description, typically by averaging the vectors of its constituent words~\cite{pardos10.1145/3330430.3333622}.

Despite this advancement, these models produce static embeddings where each word is assigned a single, fixed vector regardless of its context~\cite{devlin2019bertpretrainingdeepbidirectional}.  This is a significant drawback, as it fails to account for polysemy---words with multiple meanings.  For instance, the word ``bank'' would have the same vector in ``river bank'' and ``bank account.'' Furthermore, the practice of averaging all word vectors to create a document-level representation is a crude heuristic that can dilute or lose crucial semantic information~\cite{reimers-2019-sentence-bert}.

\section{Contextual Semantic Representations}\label{ch:2.3}
The introduction of the transformer architecture, specifically models like Bidirectional Encoder Representations from Transformers (BERT), revolutionized NLP by enabling the generation of contextual embeddings~\cite{devlin2019bertpretrainingdeepbidirectional}.  In these models, a word's vector representation is dynamically influenced by the words surrounding it, allowing the model to disambiguate word meanings and capture a much richer semantic representation~\cite{devlin2019bertpretrainingdeepbidirectional}.Architectures such as Sentence-BERT (SBERT) were subsequently developed to fine-tune these models to produce semantically meaningful embeddings for entire sentences or paragraphs, which can then be efficiently compared using metrics like cosine similarity~\cite{reimers-2019-sentence-bert}.

\section{Direct LLM Classification}\label{ch:2.4}
A more recent evolution involves the direct application of large-scale generative models, or Large Language Models (LLMs) like GPT-4 and Gemini, for classification.  As explored in preliminary work for this thesis, these models can be instructed via prompt engineering and in-context learning to perform pairwise comparisons of course descriptions and render a judgment on their equivalency.  While these experiments yielded promising accuracy, they also uncovered significant practical limitations.

The direct use of proprietary, API-based LLMs for this task is operationally and economically challenging. Each pairwise comparison requires a separate API call, which incurs both financial cost and significant latency~\cite{Sharma_2025,nvidia_2025}. For a system that needs to compare thousands of courses across hundreds of institutions, the cumulative cost and time would be prohibitive~\cite{Sharma_2025,nvidia_2025}. Furthermore, to ensure a responsive user experience in an interactive setting, end-to-end latency must be kept low, a target that is difficult to meet with large models under heavy load~\cite{nvidia_2025,Sharma_2025}. This makes the direct classification approach impractical for a scalable, production-level system and justifies the pivot to a more efficient, decoupled framework that performs the expensive semantic processing once (embedding generation) and then uses lightweight classifiers for rapid comparison.

Likewise, performance is acutely sensitive to prompt phrasing, a finding that aligns with a large and growing body of academic research that identifies this as a systemic challenge for LLMs~\cite{razavi2025benchmarkingpromptsensitivitylarge,zhuo-etal-2024-prosa}. Studies have formally demonstrated that even minor, semantically-equivalent changes in prompt wording can lead to drastically different outputs~\cite{razavi2025benchmarkingpromptsensitivitylarge,zhuo-etal-2024-prosa}. This brittleness and lack of robustness pose a significant challenge for deploying LLMs in high-stakes, operational systems like course articulation, where consistency and reliability are paramount. A system that produces different equivalency judgments based on trivial variations in prompt formatting is not a trustworthy tool for students or administrators, which also makes it ill-suited for handling complex one-to-many or many-to-many articulation scenarios.  This opacity makes it difficult to rank matches, set thresholds, or provide transparent justifications.

\section{Enrollment-Based Approaches}\label{ch:2.5}
Parallel research efforts have leveraged different data sources entirely.  A notable body of work has demonstrated that course similarity can be predicted by analyzing student enrollment data~\cite{pardos2018connectionistrecommendationwildutility, JiangPardosMulti2VecEDM2020}.  Models such as \emph{course2vec} learn embeddings from the patterns of which courses students take together, operating on the principle that courses taken in the same semester or sequence likely share a topical relationship~\cite{pardos2018connectionistrecommendationwildutility}.

While powerful, this behavioral approach is constrained by its reliance on large-scale, proprietary institutional datasets. This raises significant data privacy concerns, as the use of such data is fraught with ethical and legal challenges, including compliance with regulations like the Family Educational Rights and Privacy Act (FERPA) in the United States~\cite{sabourin2015}. The collection and analysis of student data, even for beneficial purposes, raises concerns about unauthorized profiling, potential for discrimination, and the risk of data breaches~\cite{sabourin2015}.

Beyond data privacy, however, a more fundamental technical limitation exists that is vital to the specific problem of inter-institutional articulation: the cold-start problem~\cite{10246926,10339320,googlerecommendation}. Enrollment-based methods are a form of collaborative filtering, a technique common in recommender systems~\cite{10246926}. A well-documented weakness of collaborative filtering is its inability to handle new users or new items for which it has insufficient interaction data~\cite{10246926,10339320,googlerecommendation}. This problem manifests directly and severely in the course articulation context. When a community college creates a new course, or when a university has no history of student transfers from a particular feeder institution, there are no co-enrollment patterns to learn from. The model is effectively blind. This is not a minor inconvenience but an essential mode of failure for the exact use case of establishing new articulation agreements. Therefore, these models suffer from a pivotal generalizability crisis when applied to the inter-institutional articulation discovery task, which potentially requires comparing institutions with sparse or non-existent transfer histories. This technical gap underscores the need for a framework that relies on public data, which is universally available.

\section{The Search for an Alternative}
This review of varied approaches reveals a primary trade-off: as models gain semantic power, they tend to become more computationally intensive, less interpretable, or more demanding of specialized or private data.  The limitations of direct LLM classification (cost, opacity) and enrollment-based methods (data privacy, limited access) point toward a gap in the existing research for a new paradigm~\cite{pardos-articulation-2019, slade10.1177/0002764213479366}.
An effective solution must harness the semantic power of large pre-trained models without inheriting their operational burdens.  The literature thus indicates a need for an intelligent, hybrid framework that decouples deep semantic representation from final classification.  This conceptual gap forms the central motivation for the methodology proposed in this thesis.  Table~\ref{tbl:taxonomy} summarizes the primary methods for determining course transferability.

\begin{table}[tb]
    \captionsetup{skip=5pt}
    \centering
    \setlength{\tabcolsep}{10pt} % Default value: 6pt
    \renewcommand{\arraystretch}{1.5}
    \caption{Comparative Taxonomy of Course Equivalency Determination Methods}\label{tbl:taxonomy}
    \resizebox{\columnwidth}{!}{
        \begin{tabular}{>{\raggedright\arraybackslash}p{2.25cm}>{\raggedright\arraybackslash}p{3cm}>{\raggedright\arraybackslash}p{1.75cm}>{\raggedright\arraybackslash}p{1.9cm}>{\raggedright\arraybackslash}p{3.75cm}>{\raggedright\arraybackslash}p{3.75cm}}
            \toprule
            Approach              
                         & Key Characteristics                                                   & Data Source(s)              & Semantic Capability & Strengths  
                                                                                   & Limitations                
   \\
            \midrule
            Manual Review                                  & Human experts (advisors, faculty) compare syllabi descriptions.
& Course Catalogs, Syllabi    & High (Human-level)  & Nuanced, context-aware, trusted by faculty.
& Extremely slow, not scalable, subjective, prone to inconsistency. \\
            Keyword/ TF-IDF                                & Bag-of-words representation, statistical term weighting.
& Course Catalogs             & None to Low         & Simple, computationally cheap, easy to implement.
& Fails to capture synonyms, context, or true semantic meaning \\
            Static\hspace{3em}Embeddings (Word2Vec/ GloVe) & Pre-trained word vectors, often averaged for document representation.
& Course Catalogs             & Medium              & Captures word-level semantics, better than TF-IDF.
& Context-insensitive, averaging vectors loses information. \\
            Enrollment-Based (e.g., course2vec)            & Embeddings learned from student co-enrollment patterns.
& Proprietary Student Records & High (Behavioral)   & Captures functional relationships between courses, highly predictive.
& Requires access to sensitive private data, not generalizable, privacy concerns.
\\
            Direct LLM Classification                      & End-to-end classification using prompt engineering.
& Course Catalogs             & Very High           & High accuracy potential, understands complex language.
& Computationally expensive, ``black box'' opacity, prompt sensitive, no quantifiable similarity score, risk of hallucinations.
\\
            Proposed Method (Embeddings + ML)              & Deep contextual embeddings as features for traditional classifiers.
& Course Catalogs             & Very High           & State-of-the-art accuracy, computationally efficient, quantifiable, uses public data only.
& Relies on the quality of the pre-trained embedding model.
\\
            \bottomrule
        \end{tabular}
    }
\end{table}